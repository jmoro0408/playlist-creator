{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import sys, os\n",
    "\n",
    "from playlist_recommender.modelling import model_pipeline\n",
    "from playlist_recommender.modelling import utils\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    RobustScaler,\n",
    "    MaxAbsScaler,\n",
    "    LabelEncoder,\n",
    ")\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [None, StandardScaler(), MinMaxScaler(), RobustScaler(), MaxAbsScaler()]\n",
    "samplers = [None, RandomOverSampler()]\n",
    "featurisers = [OneHotEncoder()]  # None doesn't work well\n",
    "classifiers = [LogisticRegression(), RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [MaxAbsScaler()]\n",
    "samplers = [RandomOverSampler()]\n",
    "featurisers = [OneHotEncoder(handle_unknown=\"ignore\")]  # None doesn't work well\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1200),\n",
    "    RandomForestClassifier(),\n",
    "    MLPClassifier(max_iter=1000),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_permuation_builer = {\n",
    "    \"scaler\": scalers,\n",
    "    \"sampler\": samplers,\n",
    "    \"featuriser\": featurisers,\n",
    "    \"classifier\": classifiers,\n",
    "}\n",
    "_keys, _values = zip(*config_permuation_builer.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scaler': MaxAbsScaler(),\n",
       "  'sampler': RandomOverSampler(),\n",
       "  'featuriser': OneHotEncoder(handle_unknown='ignore'),\n",
       "  'classifier': LogisticRegression(max_iter=1200)},\n",
       " {'scaler': MaxAbsScaler(),\n",
       "  'sampler': RandomOverSampler(),\n",
       "  'featuriser': OneHotEncoder(handle_unknown='ignore'),\n",
       "  'classifier': RandomForestClassifier()},\n",
       " {'scaler': MaxAbsScaler(),\n",
       "  'sampler': RandomOverSampler(),\n",
       "  'featuriser': OneHotEncoder(handle_unknown='ignore'),\n",
       "  'classifier': MLPClassifier()}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_permutations = [dict(zip(_keys, v)) for v in itertools.product(*_values)]\n",
    "config_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.prep_playlist_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.35, random_state=0, stratify=y, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different transformation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transformation(X, y, config):\n",
    "    pipe = model_pipeline.make_config_pipeline(X, config)\n",
    "    scores = cross_val_score(pipe, X, y, cv=5, scoring=\"f1_macro\")\n",
    "    f1_score = np.mean(scores)\n",
    "    print(f\"F1 score: {f1_score:.3f}\")\n",
    "    return f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.376\n",
      "F1 score: 0.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/playlist-creator/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/playlist-creator/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/playlist-creator/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/playlist-creator/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/playlist-creator/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "_values_list = []\n",
    "for config in config_permutations:\n",
    "    if config[\"featuriser\"] is None:\n",
    "        X = X.drop(\"artist_names\", axis=1)\n",
    "    f1_score = test_transformation(X, y, config)\n",
    "    _values = [str(x) for x in config.values()]\n",
    "    _values.append(f1_score)\n",
    "    _values_list.append(_values)\n",
    "\n",
    "config_df = pd.DataFrame(\n",
    "    _values_list, columns=[\"scaler\", \"sampler\", \"featuriser\", \"classifier\", \"f1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('playlist-creator')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b97f23f03363feb2857c74f4f539da46bfa500aff7c41ef02bb3fdf24f6c2adf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
