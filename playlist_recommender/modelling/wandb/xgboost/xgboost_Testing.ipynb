{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from playlist_recommender.modelling import model_pipeline\n",
    "from playlist_recommender.modelling import utils\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import compute_class_weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline dumped\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1571, 862), (846, 862), (1571,), (846,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = utils.prep_playlist_df()\n",
    "X_train, X_test, y_train, y_test = model_pipeline.make_best_transformation_pipeline(\n",
    "    X, y\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight = 'balanced',\n",
    "                                                 classes = np.unique(y_train),\n",
    "                                                 y = y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict_weights = []\n",
    "for train in y_train:\n",
    "    train_dict_weights.append(class_weight_dict[train])\n",
    "\n",
    "#XGBoost needs a weight per row, not per target feature\n",
    "    \n",
    "test_dict_weights = []\n",
    "for test in y_test:\n",
    "    test_dict_weights.append(class_weight_dict[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(train_dict_weights) == y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(test_dict_weights) == y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "config_defaults = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"subsample\": 1,\n",
    "}\n",
    "# fit model on train\n",
    "model = XGBClassifier(\n",
    "    booster=config_defaults[\"booster\"],\n",
    "    max_depth=config_defaults[\"max_depth\"],\n",
    "    learning_rate=config_defaults[\"learning_rate\"],\n",
    "    subsample=config_defaults[\"subsample\"],\n",
    "     eval_metric=['merror','mlogloss']\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "          sample_weight = train_dict_weights,\n",
    "          eval_set = [(X_test,y_test)], \n",
    "          sample_weight_eval_set = [test_dict_weights], \n",
    "          verbose = False)\n",
    "\n",
    "# make predictions on test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = metrics.f1_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "recall = metrics.recall_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2942595228672323,\n",
       " 0.2907801418439716,\n",
       " 0.292014687760366,\n",
       " 0.32174085063768054)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score, accuracy, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('playlist-creator')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b97f23f03363feb2857c74f4f539da46bfa500aff7c41ef02bb3fdf24f6c2adf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
